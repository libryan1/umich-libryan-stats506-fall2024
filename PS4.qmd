---
title: "Stats 506 Problem Set 4"
format: html
editor: visual
---

### Problem 1 - Tidyverse

```{r}
library(nycflights13)
```

a.  

```{r}
# Load in airport and departure data
airports <- nycflights13::airports
flights <- nycflights13::flights

library(dplyr)

## Table of departure delays
# Remove fights with unknown departure delays
flights2 <- filter(flights, is.na(dep_delay) == FALSE)

# Get mean and median departure delays for each origin in flights
dep_delays <- flights2 %>%
  group_by(origin) %>%
  summarise(dep_delay_mean = mean(dep_delay), dep_delay_median = median(dep_delay)) 

# Join dataframe of airports' code and name columns to departure delays dataframe such that 
# only airport codes present in origin column of departure delays dataframe are kept
dep_delays <- inner_join(airports[c('faa', 'name')], dep_delays, by = join_by(faa == origin))

# Remove airport codes
dep_delays <- mutate(dep_delays, faa = NULL)

# Sort by descending mean dep delay
dep_delays <- arrange(dep_delays, desc(dep_delay_mean))

# Print dataframe with mean and median delays and airport names as a tibble
print(as_tibble(dep_delays), n = dim(dep_delays)[1])


## Table of arrival delays
# Remove flights that never arrived
flights3 <- filter(flights, is.na(arr_delay) == FALSE)

# Get mean and median arrival times for each destination
arr_delays <- flights3 %>% 
  group_by(dest) %>%
  summarise(n_arrivals = length(arr_delay), arr_delay_mean = mean(arr_delay), arr_delay_median = median(arr_delay)) %>%
  arrange(desc(arr_delay_mean)) # Sort by descending mean arrival delay

# Remove destinations with less than 10 arrivals
arr_delays <- filter(arr_delays, n_arrivals >= 10)

# Join dataframe of airports' codes and names to arr_delays matching airports$faa column to 
# arr_delays$dest column
arr_delays <- inner_join(airports[c('faa', 'name')], arr_delays, by = join_by(faa == dest))

# Remove airport codes and number of arriving flights
arr_delays <- mutate(arr_delays, faa = NULL, n_arrivals = NULL)

# Sort by descending mean arr delay
arr_delays <- arrange(arr_delays, desc(arr_delay_mean))

# Print arr_delays as tibble
print(as_tibble(arr_delays), n = dim(arr_delays)[1])
```

b.  

```{r}
# Load in plane data
planes <- nycflights13::planes

# Get number of flights for each tailnum
n_flights_df <- flights %>%
  group_by(tailnum) %>%
  summarise(n_flights = length(flight))

# For all rows in n_flights_df join to columns tailnum, manufacturer, model, and speed from 
# planes dataframe
n_flights_df <- right_join(planes[, c('tailnum', 'manufacturer', 'model', 'speed')], n_flights_df, by = 'tailnum')

# Remove missing speeds
n_flights_df <- filter(n_flights_df, is.na(speed) == FALSE)

# Get average speed for all models of aircraft
n_flights_df <- n_flights_df %>%
  group_by(manufacturer, model) %>%
  summarise(avg_speed = mean(speed), n_flights = sum(n_flights), .groups = 'keep') %>%
  arrange(desc(avg_speed)) # Sort by descending average speed

# I kept the manufacturer column because it is typical to include the name of the manufacturer 
# when referring to planes e.g. Boeing 737 MAX
print(as_tibble(n_flights_df[1, ]))
```

### Problem 2 - get_temp()

```{r}
# Load in data
nmmaps <- read.csv('Datasets/chicago-nmmaps.csv')

# Initialize function
get_temp <- function(month, year, data, celsius = FALSE, average_fn = mean) {
  
  
  # Sanitizing month
    # Get valid month strings
  months = c('jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec', 
             'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 
             'september', 'october', 'november', 'december') 
  
    # Validate numeric month input (number or string)
      # Ensure numeric inputs are a valid month
  if (is.numeric(month) == TRUE) {
    if (month < 1 | month > 12) {
      stop('Invalid month')
    }
      # Ensure numerical strings are a valid month
  } else if (grepl('[^0-9.]', month) == FALSE) {
    if (as.numeric(month) < 1 | as.numeric(month) > 12) {
      stop('Invalid month')
    }
      # Ensure strings are a valid month (not case-sensitive)
  } else if (tolower(month) %in% months == FALSE) {
    stop('Invalid month')
  }
  
  
  # Sanitizing data
    # Must be sanitized before year or checking for range doesn't work
  if (is.data.frame(data) == FALSE) {
    stop('data must be a data.frame')
  }
  
  
  # Sanitizing year
    # Ensure numeric year input exists in data
  if (is.numeric(year) == TRUE) {
    if (year %in% data$year == FALSE) {
      stop('year outside of range')
    }
    # Ensure numerical string year exists in data
  } else if (grepl('[^0-9.]', year) == FALSE) {
    if (as.numeric(year) %in% data$year == FALSE) {
      stop('year outside of range')
    }
    # Non numerical strings are not a valid year
  } else if (grepl('[^0-9.]', year) == TRUE) {
    stop('Invalid year')
  }
  
  
  # Sanitizing celsius
  if (is.logical(celsius) == FALSE) {
    stop('celsius must be logical')
  }
  
  
  # Sanitizing average_fn
  if (is.function(average_fn) == FALSE) {
    stop('average_fn must be a valid function')
  }
  
  
  # Convert to celsius if specified
  if (celsius == TRUE) {
   data <- mutate(data, temp = (temp - 32) / 1.8)
  }
  
  
  # Group by month and year, compute avg temps
  data <- data %>% 
    group_by(month, month_numeric, year) %>%
    summarise(avg_temp = average_fn(temp), .groups = 'keep')
  
  
  # Return avg temp for specified month and year
    # Convert year to numeric if not
      # All years are represented using numeric symbols
  if (is.numeric(year) == FALSE) {
    year_filter <- as.numeric(year)
  } else {
    year_filter <- year
  }

    # Return correct avg temp by month
      # If month is numeric
  if (is.numeric(month) == TRUE) {
    month_filter <- month
    return(filter(data, month_numeric == month_filter & year == year_filter)$avg_temp)
      # If month is numerical string
  } else if (grepl('[^0-9]', month) == FALSE) {
    month_filter <- as.numeric(month)
    return(filter(data, month_numeric == month_filter & year == year_filter)$avg_temp)
      # If month is month name string
  } else {
      # Get suffixes of each month and its representation in month column
    month_vec <- c('jan' = 'Jan', 'feb' = 'Feb', 'mar' = 'Mar', 'apr' = 'Apr', 'may' = 'May', 
                   'jun' = 'Jun', 'jul' = 'Jul', 'aug' = 'Aug', 'sep' = 'Sep', 'oct' = 'Oct', 
                   'nov' = 'Nov', 'dec' = 'Dec')
      # Iterate through possible suffixes, if month input has suffix return avg temp for that 
      # month
    for (month_str in names(month_vec)) {
      if (grepl(month_str, tolower(month)) == TRUE)
        return(filter(data, month == month_vec[month_str] & year == year_filter)$avg_temp)
    }
  }
}
```

```{r, error=TRUE}
# Load in data again as nnmaps because that what this code uses as name of dataset
nnmaps <- read.csv('Datasets/chicago-nmmaps.csv')

# Testing
get_temp("Apr", 1999, data = nnmaps)
get_temp("Apr", 1999, data = nnmaps, celsius = TRUE)
get_temp(10, 1998, data = nnmaps, average_fn = median)
get_temp(13, 1998, data = nnmaps)
get_temp(2, 2005, data = nnmaps)
get_temp("November", 1999, data =nnmaps, celsius = TRUE,
         average_fn = function(x) {
           x %>% sort -> x
           x[2:(length(x) - 1)] %>% mean %>% return
         })
```

### Problem 3 - Visualization

```{r}
art_sales <- read.csv('Datasets/df_for_ml_improved_new_market.csv')
library(ggplot2)
```
a. 

```{r}
ggplot(art_sales, aes(x = factor(year), y = price_usd)) + geom_point() + 
  labs(title = 'Prices of Art (USD) vs Year') + xlab('Year') + ylab('Price (USD)') + theme_bw()
```
From the above graph we see that over the years the maximum of art prices has increased significantly.  Overall this does suggest that art prices have increased over time, but it is important to note that there are many art pieces in 2012 (the most recent year) within the range of the prices for art from 1997.  The variability could have just increased, while the actual overall prices for art may have remained constant.

b.

```{r}
# Creates a column containing the genre of each art
  # Initialize vector that will store this column's information
genre <- rep(0, dim(art_sales)[1])

  # Iterate through each art 
for (i in 1:dim(art_sales)[1]) {
    # Initialize vector that will store all of a possible work of art's genres
  genre_vec <- rep(NA, 5)
  
    # If art has a 1 in one of these categories, add it to genre_vec vector in 
    # a specific index (1 is for photography, 2 for print, etc.)
  ifelse(art_sales$Genre___Photography[i] == 1, genre_vec[1] <- 'Photography', NA)
  ifelse(art_sales$Genre___Print[i] == 1, genre_vec[2] <- 'Print', NA)
  ifelse(art_sales$Genre___Sculpture[i] == 1, genre_vec[3] <- 'Sculpture', NA)
  ifelse(art_sales$Genre___Painting[i] == 1, genre_vec[4] <- 'Painting', NA)
  ifelse(art_sales$Genre___Others[i] == 1, genre_vec[5] <- 'Others', NA)
  
    # Remove all indices that were NA (art piece didn't have it as a genre)
  genre_vec <- genre_vec[!is.na(genre_vec)]
  
    # Combine into a single string that classifies art based on which genres it
    # was (ie. a painting and others is Painting/Others)
  genre_str <- paste(genre_vec, collapse = '/')
  
    # Add genre string to genre vector
  genre[i] <- genre_str
}
  
  # Add genre column
art_sales$genre <- genre

ggplot(art_sales, aes(x = factor(year), fill = genre)) + geom_bar(position = 'fill') + 
  labs(title = 'Proportion of Sold Art Genres by Year') + xlab('Year') + ylab('Proportion') + theme_minimal()
```
The distribution of genre of sales does appear to change over time.  From the chart we can see that as the years went on the proportion of art sold classified as both "Painting" and "Others" has decreased significantly, from comprising almost half of art sold in 1997 to less than a quarter in 2012.  Additionally, the proportion of art that were "Print" only started to be sold starting in 2000.  Similarly, art that were only "Others" only started to be sold in 2007.  "Photography" has also increased since 1997, going from less than a quarter of art sales in 1997 to over a quarter in 2012.  "Sculpture" sales seem to have either remained constant or changed very little between 1997 and 2012.

c.

```{r}
ggplot(art_sales, aes(x = year, y = price_usd)) + geom_point() + 
  facet_wrap(vars(genre), strip.position = 'bottom') + 
  labs(title = 'Art Sale Price (USD) vs Year by Art Genre') + xlab('Year') + ylab('Price (USD)')
```
For all of the genres there is a common pattern that the prices the art was being sold for in 1997, many art pieces are being sold for a similar price in 2012.  However, for all of the genres except "Others", there is increased variability as more and more art prices are being sold at significantly higher values.  This is especially evident in photography, which shows the most variability with generally higher prices and more frequent pieces with higher prices.  Painting/Others and Sculpture are middle of the pack, with Print pieces while being higher than the first year they appear, not increasing as much as compared to the other three.  Overall this suggests that for all art genres except "Others" prices have increased, especially for "Photography" pieces.
